{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar10_Carney.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMSn67px4ANI",
        "toc": true
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Notebook-Configuration\" data-toc-modified-id=\"Notebook-Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Notebook Configuration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Google-drive\" data-toc-modified-id=\"Google-drive-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Google drive</a></span></li><li><span><a href=\"#Warning\" data-toc-modified-id=\"Warning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Warning</a></span></li><li><span><a href=\"#Matplotlib\" data-toc-modified-id=\"Matplotlib-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Matplotlib</a></span></li><li><span><a href=\"#TensorFlow\" data-toc-modified-id=\"TensorFlow-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>TensorFlow</a></span></li><li><span><a href=\"#Random-seed\" data-toc-modified-id=\"Random-seed-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Random seed</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Testing-the-Best-Model\" data-toc-modified-id=\"Testing-the-Best-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Testing the Best Model</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ-IbZqAgILJ"
      },
      "source": [
        "# Notebook Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3yB94KtgMHu"
      },
      "source": [
        "## Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmYBTOwgNs-",
        "scrolled": true,
        "outputId": "cd80eec9-1131-4cc0-85b4-b34e58ea9fbb"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the absolute path of the current folder\n",
        "abspath_curr = '/content/drive/My Drive/Homework_4/'\n",
        "\n",
        "# Get the absolute path of the deep utilities folder\n",
        "abspath_util_deep = '/content/drive/My Drive/ColabNotebooks'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZhU1Wqgmqx"
      },
      "source": [
        "## Warning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUl4k83e4ANR"
      },
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WMODpPfgn2U"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBRVH9SB4ANb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Set matplotlib sizes\n",
        "plt.rc('font', size=20)\n",
        "plt.rc('axes', titlesize=20)\n",
        "plt.rc('axes', labelsize=20)\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('legend', fontsize=20)\n",
        "plt.rc('figure', titlesize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-wNDk5nZhhO"
      },
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjG43tEnZkfE"
      },
      "source": [
        "# The magic below allows us to use tensorflow version 2.x\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FN3UNfO2Z7"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSADk0hJP71d"
      },
      "source": [
        "# The random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Set random seed in tensorflow\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# Set random seed in numpy\n",
        "import numpy as np\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eOpQpPu4ANk"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-Mwc6MczlFD",
        "outputId": "5544281b-693e-40ff-fbb5-fa3db05358a3"
      },
      "source": [
        "# Change working directory to the absolute path of the deep utilities folder\n",
        "%cd $abspath_util_deep\n",
        "\n",
        "# Import the deep utitilities\n",
        "%run pmlm_utilities_deep.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ColabNotebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoV7Ln06AUO9"
      },
      "source": [
        "Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CvPpuebASMz"
      },
      "source": [
        "import os\n",
        "\n",
        "# Make directory\n",
        "directory = os.path.dirname(abspath_curr + '/data/')\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs0Y8aKGASPZ"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Get the name of the data\n",
        "data_name = 'cifar10'\n",
        "\n",
        "# Load data\n",
        "data, info = tfds.load(name=data_name,\n",
        "                       data_dir=abspath_curr + '/data/',\n",
        "                       as_supervised=True,\n",
        "                       with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0IuSzdiASSH"
      },
      "source": [
        "target = 'label'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPn5aUHIASUu",
        "outputId": "c19f970e-916f-4b4a-95fa-bf015241fa3f"
      },
      "source": [
        "# Print the splits\n",
        "info.splits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <tfds.core.SplitInfo num_examples=10000>,\n",
              " 'train': <tfds.core.SplitInfo num_examples=50000>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc07uM3-ASXU",
        "outputId": "95054da5-8f6e-4876-edac-7b6de0012dd1"
      },
      "source": [
        "# Get the classes\n",
        "classes = info.features['label'].names\n",
        "\n",
        "# Print the classes\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb3wZd1PASZq",
        "outputId": "627dbbb8-4877-4ee6-881c-6ad1aefc2190"
      },
      "source": [
        "# Get the number of classes\n",
        "n_classes = info.features['label'].num_classes\n",
        "\n",
        "# Print the number of classes\n",
        "info.features['label'].num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR6WkNvVAsk9"
      },
      "source": [
        "Getting the training, validation, and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3WA50KsAScI"
      },
      "source": [
        "# Set the training, validation and test split\n",
        "split_train, split_valid, split_test = 'train[:70%]', 'train[70%:]', 'test'\n",
        "\n",
        "# Get the training data\n",
        "data_train = tfds.load(name=data_name,\n",
        "                       split=split_train,\n",
        "                       data_dir=abspath_curr + '/data/',\n",
        "                       as_supervised=True)\n",
        "\n",
        "# Get the validation data\n",
        "data_valid = tfds.load(name=data_name,\n",
        "                       split=split_valid,\n",
        "                       data_dir=abspath_curr + '/data/',\n",
        "                       as_supervised=True)\n",
        "\n",
        "# Get the test data\n",
        "data_test = tfds.load(name=data_name,\n",
        "                      split=split_test,\n",
        "                      data_dir=abspath_curr + '/data/',\n",
        "                      as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECi9xo-8Aq1O"
      },
      "source": [
        "# Call preprocess\n",
        "# See the implementation in pmlm_utilities_deep.ipynb\n",
        "\n",
        "# Normalize the training data\n",
        "data_train = data_train.map(normalize)\n",
        "\n",
        "# Normalize the validation data\n",
        "data_valid = data_valid.map(normalize)\n",
        "\n",
        "# Normalize the test data\n",
        "data_test = data_test.map(normalize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cHFAQDIAq3t"
      },
      "source": [
        "# Shuffling the training data\n",
        "data_train = data_train.shuffle(buffer_size=1000, seed=42)\n",
        "\n",
        "# Set the batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Batch and prefetch the training data\n",
        "data_train = data_train.batch(batch_size).prefetch(1)\n",
        "\n",
        "# Batch and prefetch the validation data\n",
        "data_valid = data_valid.batch(batch_size).prefetch(1)\n",
        "\n",
        "# Batch and prefetch the test data\n",
        "data_test = data_test.batch(batch_size).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6iqu0kUez-E"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aowuD9CnSeMn"
      },
      "source": [
        "# Make directory\n",
        "directory = os.path.dirname(abspath_curr + '/result/model/')\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sm-oHeGA545",
        "outputId": "e6916c11-35f5-4c2c-af22-2810b0cb77e9"
      },
      "source": [
        "# A sequential dnn\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# Add the input layer\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "# Add bn layer\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Add the first hidden layer\n",
        "model.add(keras.layers.Dense(60, activation='relu'))\n",
        "# Add bn layer\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Add the second hidden layer\n",
        "model.add(keras.layers.Dense(60, activation='relu'))\n",
        "# Add bn layer\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# Add the output layer\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# The model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 3072)              12288     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 60)                184380    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 60)                240       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 60)                3660      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 60)                240       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                610       \n",
            "=================================================================\n",
            "Total params: 201,418\n",
            "Trainable params: 195,034\n",
            "Non-trainable params: 6,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r_CbfimA57O"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.SGD(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdY0VEyzA59A"
      },
      "source": [
        "# ModelCheckpoint callback\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=abspath_curr + '/result/model/model.h5',\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only=True)\n",
        "\n",
        "# EarlyStopping callback\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "# ReduceLROnPlateau callback\n",
        "reduce_lr_on_plateau_cb = keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.1,\n",
        "    patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhNJNlp9BBnc",
        "outputId": "ad51c78f-116e-4941-906c-7f9d89af0d05"
      },
      "source": [
        "# Train, evaluate and save the best model\n",
        "history = model.fit(data_train,\n",
        "                    epochs=10,\n",
        "                    validation_data=data_valid,\n",
        "                    callbacks=[model_checkpoint_cb,\n",
        "                               early_stopping_cb,\n",
        "                               reduce_lr_on_plateau_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2188/2188 [==============================] - 16s 7ms/step - loss: 1.9743 - accuracy: 0.3046 - val_loss: 1.6510 - val_accuracy: 0.4139\n",
            "Epoch 2/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.6999 - accuracy: 0.3970 - val_loss: 1.5716 - val_accuracy: 0.4378\n",
            "Epoch 3/10\n",
            "2188/2188 [==============================] - 11s 5ms/step - loss: 1.6311 - accuracy: 0.4207 - val_loss: 1.5273 - val_accuracy: 0.4578\n",
            "Epoch 4/10\n",
            "2188/2188 [==============================] - 11s 5ms/step - loss: 1.5890 - accuracy: 0.4392 - val_loss: 1.5075 - val_accuracy: 0.4675\n",
            "Epoch 5/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.5567 - accuracy: 0.4520 - val_loss: 1.4942 - val_accuracy: 0.4711\n",
            "Epoch 6/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.5394 - accuracy: 0.4566 - val_loss: 1.4727 - val_accuracy: 0.4775\n",
            "Epoch 7/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.5099 - accuracy: 0.4681 - val_loss: 1.4643 - val_accuracy: 0.4791\n",
            "Epoch 8/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.4878 - accuracy: 0.4772 - val_loss: 1.4403 - val_accuracy: 0.4922\n",
            "Epoch 9/10\n",
            "2188/2188 [==============================] - 10s 5ms/step - loss: 1.4665 - accuracy: 0.4808 - val_loss: 1.4300 - val_accuracy: 0.4941\n",
            "Epoch 10/10\n",
            "2188/2188 [==============================] - 11s 5ms/step - loss: 1.4440 - accuracy: 0.4890 - val_loss: 1.4286 - val_accuracy: 0.4959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ6HlWXKBBsI"
      },
      "source": [
        "# Make directory\n",
        "directory = os.path.dirname(abspath_curr + '/result/figure/')\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkGivY_MA6m1"
      },
      "source": [
        "# Testing the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSIS6MeWSeMn"
      },
      "source": [
        "# Load the saved model\n",
        "model.load_weights(filepath=abspath_curr + '/result/model/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWM6wACfBUql",
        "outputId": "b62840fe-c92d-45cc-fc8a-03ebf3afc007"
      },
      "source": [
        "loss, accuracy = model.evaluate(data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 3s 4ms/step - loss: 1.4133 - accuracy: 0.5025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVtVLqZ7BZ4H"
      },
      "source": [
        "# *References*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRYtvw5uBd68"
      },
      "source": [
        "https://github.com/yuxiaohuang/teaching/tree/master/gwu/machine_learning_I/spring_2021\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/cifar10"
      ]
    }
  ]
}